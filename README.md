# ğŸ” Privacy Policy Scraper

This Python script scrapes privacy policy links and content from a list of websites and exports the data to a CSV file.
## ğŸ“¥ Clone & Run

```bash
git clone https://github.com/msnabiel/privacy-policy.git
cd privacy-policy
python main.py
```

## ğŸ“‚ Project Structure

```

privacy-scrape/
â”œâ”€â”€ claude/                     # Output folder for CSVs
â”‚   â”œâ”€â”€ privacy\_policies.csv
â”‚   â””â”€â”€ privacy\_policies\_summary.csv
â”œâ”€â”€ main.py                     # Main scraping script
â”œâ”€â”€ websites.py                 # List of websites to scan
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ .venv/                      # Local virtual environment (ignored)

````

## ğŸš€ Features

- Automatically detects privacy policy URLs from given websites
- Extracts up to 10,000 characters of visible text content
- Saves results to a CSV file
- Supports `.venv` Python environments

## ğŸ“¦ Requirements

install dependencies:

```bash
pip install -r requirements.txt
````

If `requirements.txt` doesnâ€™t exist, install manually:

```bash
pip install requests beautifulsoup4 tldextract
```

## ğŸ§  How It Works

* `main.py` reads URLs from `websites.py`
* For each site, it:

  1. Finds a link containing the word "privacy"
  2. Visits that link and extracts visible text
  3. Saves the company name, policy URL, and text to CSV

## ğŸ› ï¸ Usage

```bash
python main.py
```

Output will be saved as:

* `privacy_policies.csv` â€“ Raw text data
* `privacy_policies_summary.csv` â€“ (Optional) Summarized version if implemented

## ğŸ“„ License

MIT License
